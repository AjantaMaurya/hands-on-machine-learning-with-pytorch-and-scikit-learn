{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Project 2:  Mnist Classification"
      ],
      "metadata": {
        "id": "gK_GjxO6NqYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<li>Classification Project</li>\n",
        "<li>MNIST hand-written digits</li>"
      ],
      "metadata": {
        "id": "RDttjw5f1Eb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset"
      ],
      "metadata": {
        "id": "mV1p68eL1mIs"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "YxH4tEZv3Xr8"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "cBXRqsJU08Xc"
      },
      "outputs": [],
      "source": [
        "#Step 1\n",
        "#Load the data set and specify the hyper parameters(size of train and test set and the size of mini-batches)\n",
        "import torchvision\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/content/drive/MyDrive/MNIST'\n",
        "transform = transforms.Compose([transforms.ToTensor()])#the ToTensor() converts the pixels into floating type tensor and also normalizes\n",
        "#the pixels from [0, 255] to [0, 1]range"
      ],
      "metadata": {
        "id": "Z6to9yko3qwR"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train_dataset = torchvision.datasets.MNIST(root = image_path, train= True, transform=transform, download = False)"
      ],
      "metadata": {
        "id": "bI-uvUWO4d3L"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_test_dataset = torchvision.datasets.MNIST(root = image_path, train= False, transform=transform, download = False)"
      ],
      "metadata": {
        "id": "ZHdYOqdc5AS3"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "torch.manual_seed(1)\n",
        "train_dl = DataLoader(mnist_train_dataset, batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "x6EosnCc5IZ8"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 2 , done above with ToTensor"
      ],
      "metadata": {
        "id": "xKm8NsKK5lXz"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3.\n",
        "#Construct the NN model\n",
        "hidden_units = [32, 16]\n",
        "image_size = mnist_train_dataset[0][0].shape\n",
        "input_size = image_size[0] * image_size[1] * image_size[2]\n",
        "all_layers = [nn.Flatten()]\n",
        "for hidden_unit in hidden_units:\n",
        "  layer = nn.Linear(input_size, hidden_unit)\n",
        "  all_layers.append(layer)\n",
        "  all_layers.append(nn.ReLU())\n",
        "  input_size = hidden_unit\n",
        "all_layers.append(nn.Linear(hidden_units[-1], 10))# 10 classes for output\n",
        "model = nn.Sequential(*all_layers)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGPqmj5x6yzj",
        "outputId": "dc0a1d01-193a-4c38-8ef4-f36901be0f04"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Flatten(start_dim=1, end_dim=-1)\n",
              "  (1): Linear(in_features=784, out_features=32, bias=True)\n",
              "  (2): ReLU()\n",
              "  (3): Linear(in_features=32, out_features=16, bias=True)\n",
              "  (4): ReLU()\n",
              "  (5): Linear(in_features=16, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = mnist_train_dataset[0][0].shape\n",
        "print(image_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cum-C_L17b04",
        "outputId": "aef0a16d-1b82-4bc8-bfcc-e843545cc4eb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 4\n",
        "#using the model to train, evaluate and predict\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "torch.manual_seed(1)\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "  accuracy_hist_train = 0\n",
        "  for x_batch, y_batch in train_dl:\n",
        "    pred = model(x_batch)\n",
        "    loss = loss_fn(pred, y_batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    is_correct = (torch.argmax(pred, dim = 1) == y_batch).float()\n",
        "    accuracy_hist_train += is_correct.sum()\n",
        "  accuracy_hist_train /= len(train_dl.dataset)\n",
        "  print(f'Epoch {epoch} Accuracy 'f'{accuracy_hist_train:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_WK1QS97f1N",
        "outputId": "7351a3a5-6aef-406b-9bd9-398754b804e1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Accuracy 0.8531\n",
            "Epoch 1 Accuracy 0.9287\n",
            "Epoch 2 Accuracy 0.9413\n",
            "Epoch 3 Accuracy 0.9506\n",
            "Epoch 4 Accuracy 0.9558\n",
            "Epoch 5 Accuracy 0.9592\n",
            "Epoch 6 Accuracy 0.9627\n",
            "Epoch 7 Accuracy 0.9649\n",
            "Epoch 8 Accuracy 0.9673\n",
            "Epoch 9 Accuracy 0.9690\n",
            "Epoch 10 Accuracy 0.9711\n",
            "Epoch 11 Accuracy 0.9729\n",
            "Epoch 12 Accuracy 0.9737\n",
            "Epoch 13 Accuracy 0.9747\n",
            "Epoch 14 Accuracy 0.9766\n",
            "Epoch 15 Accuracy 0.9778\n",
            "Epoch 16 Accuracy 0.9780\n",
            "Epoch 17 Accuracy 0.9798\n",
            "Epoch 18 Accuracy 0.9806\n",
            "Epoch 19 Accuracy 0.9816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model(mnist_test_dataset.data/255.)\n",
        "is_correct = (torch.argmax(pred, dim = 1) == mnist_test_dataset.targets).float()\n",
        "print(f'Test accuracy: {is_correct.mean():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnbOs3Lp-_nE",
        "outputId": "c671474e-2d06-4067-f5ef-b6ffb0a07b57"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.9645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QumisfTmNwZZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}